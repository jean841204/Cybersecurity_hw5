"""
AI æ–‡æœ¬æª¢æ¸¬å™¨ - Streamlit æ‡‰ç”¨ç¨‹å¼
æª¢æ¸¬æ–‡å­—å…§å®¹æ˜¯å¦ç”± AI ç”Ÿæˆ

å„ªåŒ–è¦é»ï¼š
1. ä½¿ç”¨ @st.cache_resource å¿«å–æ¨¡å‹ï¼ˆåªè¼‰å…¥ä¸€æ¬¡ï¼‰
2. ä½¿ç”¨ @st.cache_data å¿«å–æª¢æ¸¬çµæœ
3. é™åˆ¶æ–‡æœ¬é•·åº¦é¿å…è™•ç†æ™‚é–“éé•·
4. æä¾›é€²åº¦æŒ‡ç¤º
5. åˆ†æ®µè™•ç†é•·æ–‡æœ¬
"""

import streamlit as st
import plotly.graph_objects as go
import time
from utils.model_loader import (
    load_detector_model,
    predict_ai_text,
    chunk_text,
    batch_predict,
    get_model_info
)
from utils.text_analyzer import (
    analyze_text_features,
    get_ai_indicators,
    get_confidence_color,
    format_percentage
)

# é é¢é…ç½®
st.set_page_config(
    page_title="AI æ–‡æœ¬æª¢æ¸¬å™¨",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾© CSS
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .warning-text {
        color: #ff6b6b;
        font-weight: bold;
    }
    .success-text {
        color: #51cf66;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# é è¼‰å…¥æ¨¡å‹ï¼ˆåœ¨é é¢é–‹å•Ÿæ™‚å°±è¼‰å…¥ï¼Œä¸ç­‰ç”¨æˆ¶é»æ“ŠæŒ‰éˆ•ï¼‰
@st.cache_resource
def initialize_app():
    """åˆå§‹åŒ–æ‡‰ç”¨ï¼Œé è¼‰å…¥æ¨¡å‹"""
    tokenizer, model = load_detector_model()
    return tokenizer, model

# åŸ·è¡Œé è¼‰å…¥
tokenizer, model = initialize_app()

# æ¨™é¡Œ
st.markdown('<div class="main-header">ğŸ¤– AI æ–‡æœ¬æª¢æ¸¬å™¨</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">æª¢æ¸¬æ–‡å­—å…§å®¹æ˜¯å¦ç”± AI ç”Ÿæˆ</div>', unsafe_allow_html=True)

# é¡¯ç¤ºæ¨¡å‹ç‹€æ…‹
if tokenizer and model:
    st.success("âœ… æ¨¡å‹å·²å°±ç·’ï¼Œå¯ä»¥é–‹å§‹æª¢æ¸¬ï¼")
else:
    st.error("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹é‡æ–°æ•´ç†é é¢")

# å´é‚Šæ¬„è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
    st.markdown("---")
    st.subheader("ğŸ¤– ä½¿ç”¨çš„æ¨¡å‹")
    model_info = get_model_info()

    with st.expander("æŸ¥çœ‹æ¨¡å‹è©³æƒ…", expanded=False):
        st.markdown(f"""
        **æ¨¡å‹åç¨±ï¼š** {model_info['name']}

        **æ¨¡å‹é¡å‹ï¼š** {model_info['type']}

        **æ¨¡å‹å¤§å°ï¼š** {model_info['size']}

        **è¨“ç·´æ•¸æ“šï¼š** {model_info['training_data']}

        **æº–ç¢ºåº¦ï¼š** {model_info['accuracy']}

        **èªªæ˜ï¼š** {model_info['description']}

        **å®Œæ•´è·¯å¾‘ï¼š** `{model_info['full_name']}`
        """)

    st.markdown("---")
    st.subheader("æ–‡æœ¬é•·åº¦é™åˆ¶")
    max_words = st.slider(
        "æœ€å¤§å­—æ•¸ï¼ˆé¿å…è™•ç†éæ…¢ï¼‰",
        min_value=100,
        max_value=2000,
        value=800,
        step=100,
        help="è¼ƒé•·çš„æ–‡æœ¬æœƒè¢«æˆªæ–·ä»¥æå‡æª¢æ¸¬é€Ÿåº¦"
    )

    st.markdown("---")
    st.subheader("æª¢æ¸¬æ¨¡å¼")
    detection_mode = st.radio(
        "é¸æ“‡æ¨¡å¼",
        ["å¿«é€Ÿæ¨¡å¼", "è©³ç´°æ¨¡å¼"],
        help="å¿«é€Ÿæ¨¡å¼ï¼šåªé€²è¡Œ AI æª¢æ¸¬\nè©³ç´°æ¨¡å¼ï¼šé¡å¤–é¡¯ç¤ºæ–‡æœ¬çµ±è¨ˆåˆ†æ"
    )

    st.markdown("---")
    st.subheader("ğŸ“Š ä½¿ç”¨çµ±è¨ˆ")
    if 'detection_count' not in st.session_state:
        st.session_state.detection_count = 0
    st.metric("ç¸½æª¢æ¸¬æ¬¡æ•¸", st.session_state.detection_count)

    st.markdown("---")
    st.info("""
    **ä½¿ç”¨æç¤ºï¼š**
    - é¦–æ¬¡ä½¿ç”¨éœ€ä¸‹è¼‰æ¨¡å‹ï¼ˆç´„ 500MBï¼‰
    - å»ºè­°æ–‡æœ¬é•·åº¦ 100-800 å­—
    - éé•·æ–‡æœ¬æœƒè‡ªå‹•æˆªæ–·
    - çµæœæœƒè¢«å¿«å–ä»¥åŠ é€Ÿé‡è¤‡æŸ¥è©¢
    """)

# ä¸»è¦å…§å®¹å€
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ“ è¼¸å…¥æ–‡æœ¬")

    # æ–‡æœ¬è¼¸å…¥æ–¹å¼é¸æ“‡
    input_method = st.radio(
        "é¸æ“‡è¼¸å…¥æ–¹å¼",
        ["ç›´æ¥è¼¸å…¥", "ä¸Šå‚³æª”æ¡ˆ"],
        horizontal=True
    )

    text_input = ""

    if input_method == "ç›´æ¥è¼¸å…¥":
        text_input = st.text_area(
            "è«‹è¼¸å…¥è¦æª¢æ¸¬çš„æ–‡å­—",
            height=300,
            placeholder="åœ¨æ­¤è¼¸å…¥æˆ–è²¼ä¸Šæ–‡å­—...",
            help=f"æœ€å¤šè™•ç† {max_words} å€‹è‹±æ–‡å–®è©"
        )
    else:
        uploaded_file = st.file_uploader(
            "ä¸Šå‚³æ–‡å­—æª”æ¡ˆ",
            type=['txt'],
            help="æ”¯æ´ .txt æ ¼å¼"
        )
        if uploaded_file is not None:
            try:
                text_input = uploaded_file.read().decode('utf-8')
                st.success(f"æˆåŠŸè®€å–æª”æ¡ˆï¼å­—æ•¸ï¼š{len(text_input.split())} è©")
                with st.expander("æŸ¥çœ‹æª”æ¡ˆå…§å®¹"):
                    st.text(text_input[:500] + "..." if len(text_input) > 500 else text_input)
            except Exception as e:
                st.error(f"æª”æ¡ˆè®€å–å¤±æ•—ï¼š{str(e)}")

    # é¡¯ç¤ºå­—æ•¸çµ±è¨ˆ
    if text_input:
        word_count = len(text_input.split())
        char_count = len(text_input)

        col_a, col_b, col_c = st.columns(3)
        with col_a:
            st.metric("å­—æ•¸", f"{word_count} è©")
        with col_b:
            st.metric("å­—å…ƒæ•¸", f"{char_count} å­—å…ƒ")
        with col_c:
            if word_count > max_words:
                st.metric("è™•ç†å­—æ•¸", f"{max_words} è©", delta=f"-{word_count - max_words}",
                         delta_color="inverse")
                st.warning(f"âš ï¸ æ–‡æœ¬éé•·ï¼Œå°‡åªåˆ†æå‰ {max_words} å€‹è©")
            else:
                st.metric("è™•ç†å­—æ•¸", f"{word_count} è©", delta="å…¨éƒ¨")

with col2:
    st.subheader("â„¹ï¸ é—œæ–¼æ­¤å·¥å…·")
    st.markdown("""
    æ­¤å·¥å…·ä½¿ç”¨é è¨“ç·´çš„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ä¾†æª¢æ¸¬æ–‡æœ¬æ˜¯å¦ç”± AI ç”Ÿæˆã€‚

    **æª¢æ¸¬åŸç†ï¼š**
    - åˆ†ææ–‡æœ¬çš„èªè¨€æ¨¡å¼
    - æ¯”å° AI ç”Ÿæˆç‰¹å¾µ
    - è¨ˆç®— AI ç”Ÿæˆæ©Ÿç‡

    **é™åˆ¶èªªæ˜ï¼š**
    - æº–ç¢ºåº¦ç´„ 85-90%
    - ç„¡æ³• 100% ç¢ºå®š
    - æ··åˆæ–‡æœ¬å¯èƒ½èª¤åˆ¤
    - æŒçºŒæ›´æ–°ä¸­

    **é©ç”¨å ´æ™¯ï¼š**
    - å­¸è¡“è«–æ–‡æª¢æŸ¥
    - ä½œæ¥­åŸå‰µæ€§å¯©æ ¸
    - å…§å®¹çœŸå¯¦æ€§é©—è­‰
    """)

# æª¢æ¸¬æŒ‰éˆ•
st.markdown("---")
if st.button("ğŸ” é–‹å§‹æª¢æ¸¬", type="primary", use_container_width=True):
    if not text_input or len(text_input.strip()) < 10:
        st.error("âŒ è«‹è¼¸å…¥è‡³å°‘ 10 å€‹å­—å…ƒçš„æ–‡æœ¬")
    else:
        # æ¨¡å‹å·²åœ¨é é¢è¼‰å…¥æ™‚é è¼‰å…¥ï¼Œç›´æ¥ä½¿ç”¨
        if tokenizer and model:
            try:
                # é–‹å§‹è¨ˆæ™‚
                start_time = time.time()

                # é€²åº¦æ¢
                progress_bar = st.progress(0)
                status_text = st.empty()

                # æ­¥é©Ÿ 1: æ–‡æœ¬é è™•ç†
                status_text.text("æ­¥é©Ÿ 1/3: æ–‡æœ¬é è™•ç†...")
                progress_bar.progress(20)

                # é™åˆ¶æ–‡æœ¬é•·åº¦
                words = text_input.split()
                if len(words) > max_words:
                    text_to_analyze = ' '.join(words[:max_words])
                else:
                    text_to_analyze = text_input

                # æ­¥é©Ÿ 2: AI æª¢æ¸¬
                status_text.text("æ­¥é©Ÿ 2/3: AI æª¢æ¸¬åˆ†æ...")
                progress_bar.progress(50)

                result = predict_ai_text(tokenizer, model, text_to_analyze)

                # æ­¥é©Ÿ 3: é¡å¤–åˆ†æï¼ˆè©³ç´°æ¨¡å¼ï¼‰
                if detection_mode == "è©³ç´°æ¨¡å¼":
                    status_text.text("æ­¥é©Ÿ 3/3: æ–‡æœ¬ç‰¹å¾µåˆ†æ...")
                    progress_bar.progress(80)
                    features = analyze_text_features(text_to_analyze)
                    indicators = get_ai_indicators(features)
                else:
                    features = None
                    indicators = []

                progress_bar.progress(100)
                status_text.text("âœ… æª¢æ¸¬å®Œæˆï¼")

                # è¨ˆç®—è€—æ™‚
                elapsed_time = time.time() - start_time

                # æ›´æ–°çµ±è¨ˆ
                st.session_state.detection_count += 1

                # é¡¯ç¤ºçµæœ
                time.sleep(0.5)  # çŸ­æš«å»¶é²ä»¥é¡¯ç¤ºå®Œæˆç‹€æ…‹
                progress_bar.empty()
                status_text.empty()

                st.markdown("---")
                st.markdown("## ğŸ“Š æª¢æ¸¬çµæœ")

                if result:
                    # ä¸»è¦çµæœé¡¯ç¤º
                    col1, col2, col3 = st.columns([2, 1, 1])

                    with col1:
                        # å„€è¡¨æ¿
                        fig = go.Figure(go.Indicator(
                            mode="gauge+number",
                            value=result['ai_probability'] * 100,
                            title={'text': "AI ç”Ÿæˆæ©Ÿç‡", 'font': {'size': 24}},
                            number={'suffix': "%", 'font': {'size': 48}},
                            gauge={
                                'axis': {'range': [None, 100], 'tickwidth': 1},
                                'bar': {'color': "darkblue"},
                                'steps': [
                                    {'range': [0, 30], 'color': "lightgreen"},
                                    {'range': [30, 70], 'color': "lightyellow"},
                                    {'range': [70, 100], 'color': "lightcoral"}
                                ],
                                'threshold': {
                                    'line': {'color': "red", 'width': 4},
                                    'thickness': 0.75,
                                    'value': 80
                                }
                            }
                        ))
                        fig.update_layout(height=300)
                        st.plotly_chart(fig, use_container_width=True)

                    with col2:
                        st.markdown("### åˆ¤å®šçµæœ")
                        if result['is_ai']:
                            st.markdown('<p class="warning-text">âš ï¸ å¯èƒ½æ˜¯ AI ç”Ÿæˆ</p>',
                                      unsafe_allow_html=True)
                        else:
                            st.markdown('<p class="success-text">âœ… å¯èƒ½æ˜¯äººé¡æ’°å¯«</p>',
                                      unsafe_allow_html=True)

                        st.markdown(f"""
                        **ä¿¡å¿ƒç­‰ç´š:** {result['confidence']}

                        **è©³ç´°æ©Ÿç‡:**
                        - AI: {format_percentage(result['ai_probability'])}
                        - äººé¡: {format_percentage(result['human_probability'])}
                        """)

                    with col3:
                        st.markdown("### æ€§èƒ½æŒ‡æ¨™")
                        st.metric("è™•ç†æ™‚é–“", f"{elapsed_time:.2f} ç§’")
                        st.metric("åˆ†æå­—æ•¸", len(text_to_analyze.split()))
                        st.metric("é€Ÿåº¦", f"{len(text_to_analyze.split())/elapsed_time:.0f} è©/ç§’")

                    # åˆ¤å®šåŸå› èˆ‡è©•æ¯”æŒ‡æ¨™
                    st.markdown("---")
                    st.markdown("### ğŸ” åˆ¤å®šåŸå› èˆ‡è©•æ¯”æŒ‡æ¨™")

                    col_reason1, col_reason2 = st.columns(2)

                    with col_reason1:
                        st.markdown("#### ğŸ“Œ æª¢æ¸¬æŒ‡æ¨™")
                        if 'indicators' in result and result['indicators']:
                            for indicator in result['indicators']:
                                st.info(f"ğŸ¯ {indicator}")
                        else:
                            st.info("ğŸ¯ åŸºæ–¼ RoBERTa æ¨¡å‹çš„èªè¨€æ¨¡å¼åˆ†æ")

                        st.markdown(f"""
                        **æ©Ÿç‡å·®è·ï¼š** {result.get('probability_difference', 0):.2%}

                        {
                            "ï¼ˆå·®è·å¤§ï¼Œåˆ¤å®šæ˜ç¢ºï¼‰" if result.get('probability_difference', 0) > 0.5
                            else "ï¼ˆå·®è·ä¸­ç­‰ï¼‰" if result.get('probability_difference', 0) > 0.2
                            else "ï¼ˆå·®è·å°ï¼Œè¼ƒä¸ç¢ºå®šï¼‰"
                        }
                        """)

                    with col_reason2:
                        st.markdown("#### ğŸ’¡ ç‚ºä»€éº¼é€™æ¨£åˆ¤å®šï¼Ÿ")
                        if 'reasons' in result and result['reasons']:
                            for i, reason in enumerate(result['reasons'], 1):
                                st.markdown(f"{i}. {reason}")
                        else:
                            st.markdown("åŸºæ–¼æ¨¡å‹è¨“ç·´çš„æ•¸ç™¾è¬å€‹æ¨£æœ¬é€²è¡Œåˆ¤æ–·")

                    # è©•æ¯”æ¨™æº–èªªæ˜
                    st.markdown("---")
                    st.markdown("### ğŸ“Š è©•æ¯”æ¨™æº–")

                    with st.expander("æ¨¡å‹å¦‚ä½•åˆ¤å®š AI æ–‡æœ¬ï¼Ÿ", expanded=True):
                        st.markdown("""
                        **RoBERTa æ¨¡å‹çš„è©•æ¯”æ©Ÿåˆ¶ï¼š**

                        1. **èªè¨€æ¨¡å¼åˆ†æ**
                           - åˆ†æå¥å­çµæ§‹å’Œè©å½™é¸æ“‡
                           - æª¢æ¸¬å…¸å‹çš„ AI ç”Ÿæˆæ¨¡å¼
                           - è­˜åˆ¥éæ–¼å®Œç¾æˆ–è¦å¾‹çš„èªæ³•

                        2. **ä¸Šä¸‹æ–‡é€£è²«æ€§**
                           - è©•ä¼°æ®µè½ä¹‹é–“çš„é‚è¼¯é€£æ¥
                           - æª¢æ¸¬è½‰æŠ˜è©çš„ä½¿ç”¨é »ç‡
                           - åˆ†æå¥å­é•·åº¦çš„ä¸€è‡´æ€§

                        3. **è©å½™ç‰¹å¾µ**
                           - è©å½™å¤šæ¨£æ€§åˆ†æ
                           - å°ˆæ¥­è¡“èªä½¿ç”¨é »ç‡
                           - å¸¸è¦‹ AI ç”¨èªæª¢æ¸¬

                        4. **å¯«ä½œé¢¨æ ¼**
                           - è­˜åˆ¥äººé¡å¯«ä½œçš„ä¸è¦å‰‡æ€§
                           - æª¢æ¸¬æƒ…æ„Ÿè¡¨é”æ–¹å¼
                           - åˆ†æå€‹äººåŒ–èªè¨€ç‰¹å¾µ

                        **æ©Ÿç‡è¨ˆç®—ï¼š**
                        - æ¨¡å‹è¼¸å‡ºå…©å€‹æ©Ÿç‡ï¼šAI æ©Ÿç‡ vs äººé¡æ©Ÿç‡
                        - ä½¿ç”¨ Softmax å‡½æ•¸æ¨™æº–åŒ–çµæœ
                        - è¼ƒé«˜æ©Ÿç‡æ±ºå®šæœ€çµ‚åˆ¤å®š
                        - æ©Ÿç‡å·®è·åæ˜ åˆ¤å®šä¿¡å¿ƒåº¦

                        **ä¿¡å¿ƒç­‰ç´šå®šç¾©ï¼š**
                        - **é«˜ä¿¡å¿ƒ**ï¼ˆ>85%ï¼‰ï¼šæ¨¡å‹éå¸¸ç¢ºå®š
                        - **ä¸­ä¿¡å¿ƒ**ï¼ˆ65-85%ï¼‰ï¼šæ¨¡å‹è¼ƒç‚ºç¢ºå®š
                        - **ä½ä¿¡å¿ƒ**ï¼ˆ<65%ï¼‰ï¼šæ¨¡å‹ä¸å¤ªç¢ºå®šï¼Œå¯èƒ½æ˜¯é‚Šç•Œæ¡ˆä¾‹
                        """)

                    # çµæœè§£é‡‹
                    st.markdown("---")
                    st.markdown("### ğŸ“ çµæœè§£é‡‹")

                    if result['ai_probability'] > 0.8:
                        st.error("""
                        **é«˜åº¦å¯ç–‘ï¼ˆ>80%ï¼‰**

                        æ­¤æ–‡æœ¬å…·æœ‰å¼·çƒˆçš„ AI ç”Ÿæˆç‰¹å¾µï¼Œå¾ˆå¯èƒ½ç”± ChatGPTã€Claude æˆ–å…¶ä»– AI å·¥å…·ç”Ÿæˆã€‚

                        å»ºè­°ï¼š
                        - ä»”ç´°å¯©æŸ¥æ–‡æœ¬å…§å®¹
                        - è¦æ±‚æä¾›å¯«ä½œéç¨‹è­‰æ˜
                        - é€²è¡Œé¢è«‡ç¢ºèªç†è§£ç¨‹åº¦
                        """)
                    elif result['ai_probability'] > 0.5:
                        st.warning("""
                        **ä¸­åº¦å¯ç–‘ï¼ˆ50-80%ï¼‰**

                        æ­¤æ–‡æœ¬å¯èƒ½åŒ…å« AI ç”Ÿæˆå…§å®¹ï¼Œæˆ–è€…å—åˆ° AI å·¥å…·çš„è¼”åŠ©ã€‚

                        å»ºè­°ï¼š
                        - çµåˆå…¶ä»–è­‰æ“šåˆ¤æ–·
                        - é—œæ³¨å…·é«”æ®µè½å…§å®¹
                        - è€ƒæ…®æ˜¯å¦ç‚º AI è¼”åŠ©å¯«ä½œ
                        """)
                    else:
                        st.success("""
                        **ä½åº¦å¯ç–‘ï¼ˆ<50%ï¼‰**

                        æ­¤æ–‡æœ¬æ›´åƒæ˜¯äººé¡è‡ªç„¶æ’°å¯«ï¼ŒAI ç”Ÿæˆçš„å¯èƒ½æ€§è¼ƒä½ã€‚

                        è¨»è¨˜ï¼š
                        - ä¸æ’é™¤é«˜å“è³ª AI æˆ–äººå·¥ç·¨è¼¯éçš„å…§å®¹
                        - å»ºè­°ç¶œåˆå…¶ä»–å› ç´ åˆ¤æ–·
                        """)

                    # è©³ç´°æ¨¡å¼ï¼šé¡¯ç¤ºçµ±è¨ˆåˆ†æ
                    if detection_mode == "è©³ç´°æ¨¡å¼" and features:
                        st.markdown("---")
                        st.markdown("### ğŸ“ˆ æ–‡æœ¬çµ±è¨ˆåˆ†æ")

                        col1, col2, col3, col4 = st.columns(4)

                        with col1:
                            st.metric("ç¸½å­—æ•¸", features['word_count'])
                            st.metric("å¥å­æ•¸", features['sentence_count'])

                        with col2:
                            st.metric("å¹³å‡å¥é•·", f"{features['avg_sentence_length']} è©")
                            st.metric("å¹³å‡è©é•·", f"{features['avg_word_length']} å­—å…ƒ")

                        with col3:
                            st.metric("è©å½™å¤šæ¨£æ€§", features['vocabulary_diversity'])
                            st.metric("æ¨™é»ç¬¦è™Ÿæ¯”", f"{features['punctuation_ratio']:.3f}")

                        with col4:
                            st.metric("å¥é•·è®Šç•°", features['sentence_variance'])
                            st.metric("è½‰æŠ˜è©æ¯”", f"{features['transition_words_ratio']:.3f}")

                        # AI æŒ‡æ¨™
                        if indicators:
                            st.markdown("#### ğŸš¨ AI å¯«ä½œæŒ‡æ¨™")
                            for indicator in indicators:
                                st.warning(f"â€¢ {indicator}")
                        else:
                            st.success("âœ… æœªç™¼ç¾æ˜é¡¯çš„ AI å¯«ä½œæŒ‡æ¨™")

                    # å…è²¬è²æ˜
                    st.markdown("---")
                    st.info("""
                    **âš ï¸ å…è²¬è²æ˜**

                    æ­¤å·¥å…·åŸºæ–¼æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ï¼Œæª¢æ¸¬çµæœåƒ…ä¾›åƒè€ƒï¼Œä¸æ‡‰ä½œç‚ºå”¯ä¸€åˆ¤æ–·ä¾æ“šã€‚
                    AI æŠ€è¡“ä¸æ–·é€²åŒ–ï¼Œæª¢æ¸¬æº–ç¢ºåº¦ç„¡æ³•é”åˆ° 100%ã€‚å»ºè­°çµåˆå…¶ä»–æ–¹æ³•ç¶œåˆåˆ¤æ–·ã€‚
                    """)

                else:
                    st.error("âŒ æª¢æ¸¬å¤±æ•—ï¼Œè«‹é‡è©¦")

            except Exception as e:
                st.error(f"âŒ æª¢æ¸¬éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
                st.info("è«‹å˜—è©¦ç¸®çŸ­æ–‡æœ¬é•·åº¦æˆ–é‡æ–°æ•´ç†é é¢")

        else:
            st.error("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥ä¸¦é‡æ–°æ•´ç†é é¢")

# é å°¾
st.markdown("---")
model_info = get_model_info()
st.markdown(f"""
<div style='text-align: center; color: #666; padding: 2rem;'>
    <p>ğŸ“ NCHU Cybersecurity - AI Text Detector</p>
    <p>Powered by Hugging Face Transformers & Streamlit</p>
    <p style='font-size: 0.8rem;'>ä½¿ç”¨æ¨¡å‹ï¼š{model_info['name']} ({model_info['full_name']})</p>
</div>
""", unsafe_allow_html=True)
